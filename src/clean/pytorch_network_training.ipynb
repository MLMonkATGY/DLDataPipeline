{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjSqDwgxsyiE"
      },
      "source": [
        "# Train a neural network for multi-label classification on the CelebA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeoyWCIYsyiG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/multilabel_classification/pytorch_network_training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfEuwy0ksyiG"
      },
      "source": [
        "This notebook demonstrates how to train a Pytorch neural network for image tagging and use the model to produce out-of-sample predicted class probabilities for each image in the dataset. These are required inputs to find label errors in multi-label classification datasets with cleanlab. Here we consider a subset of the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, where each image may be tagged with one or more of the following tags: `['Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'Eyeglasses', 'No_Beard', 'Smiling']`, depending on which ones apply to the person depicted.\n",
        "\n",
        "This notebook only shows how to train the network and use it to produce `pred_probs`, using them to find label issues is demonstrated in our other [example](https://github.com/cleanlab/examples/) notebook on [Find Label Errors in Multi-Label Classification Data (CelebA Image Tagging)](https://github.com/cleanlab/examples/blob/multilabel_tutorial/multilabel_classification/image_tagging.ipynb). Here we fit a state-of-the-art neural network initialized from a pretrained [TIMM](https://timm.fast.ai/) network backbone. You can use this same code to obtain a multi-label classifier (i.e. image tagging model) for *any* image dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNzpDVZOsyiG"
      },
      "source": [
        "Please install the dependencies specified in this [requirements.txt](https://github.com/cleanlab/examples/blob/master/multilabel_classification/requirements.txt) file before running the notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga3f-6EQsyiG"
      },
      "source": [
        "Next you need to download the dataset. The below code attempts to download the dataset from the Google Drive where its authors have stored it, but this Drive only allows limited programmatic downloads per day. If the Google Drive download script fails, please just manually download the following links from the [CelebA dataset webpage](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and save them in the current working directory:\n",
        " * [Images](https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM)\n",
        " * [Labels](https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "A_bNsVYCsyiH"
      },
      "outputs": [],
      "source": [
        "# import gdown\n",
        "# import os\n",
        "# def download_drive(url,output):\n",
        "#     filename = gdown.download(url, output, quiet=False)\n",
        "#     if filename is None:\n",
        "#         print(f\"Downloading {url} failed, please download it from browser and paste it in {os.getcwd()}\")\n",
        "# url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U'\n",
        "# output = 'list_attr_celeba.txt'\n",
        "# if not os.path.exists(output):\n",
        "#     download_drive(url,output)\n",
        "# url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM' # Usually errors out, Download them manually from the link below\n",
        "# output = 'img_align_celeba.zip'\n",
        "# if not os.path.exists(output):\n",
        "#     download_drive(url,output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHb1XrRUsyiH"
      },
      "source": [
        "Remember you can just manually download the data from the link above if this code failed. Once you have downloaded the zipped data file, unzip the folder which contains a bunch of individual image files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "a1ECAnTcsyiI"
      },
      "outputs": [],
      "source": [
        "# !unzip -qq img_align_celeba.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6feD6tYsyiI"
      },
      "source": [
        "Next we import the other required dependencies (make sure you have installed these packages)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P7PgaxmRsyiI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alextay96/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/alextay96/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/alextay96/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "from types import SimpleNamespace\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data\n",
        "from timm.optim import create_optimizer\n",
        "from timm.models import create_model\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.loader import create_loader\n",
        "from timm.utils import CheckpointSaver\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpHBLtpZsyiI"
      },
      "source": [
        "Now we load the dataset, and preprocess it to only keep the classes of interest (i.e. *image tags*) listed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cRX2LyXisyiI"
      },
      "outputs": [],
      "source": [
        "DATA =(\"image_id \" + open(\"list_attr_celeba.txt\").read()[7:]).splitlines()\n",
        "\n",
        "from collections import defaultdict\n",
        "q = DATA[0]\n",
        "d_data = defaultdict(list)\n",
        "ls = q.split()\n",
        "for i in q.split():\n",
        "    d_data[i] = []\n",
        "for j in DATA[1:]:\n",
        "    labels = j.split()\n",
        "    for k in range(0,len(labels)):\n",
        "        if k==0:\n",
        "            d_data[ls[k]].append(labels[k])\n",
        "        else:\n",
        "            # map -1 entries -> 0\n",
        "            ps = int((int(labels[k])+1)/2)\n",
        "            d_data[ls[k]].append(ps)\n",
        "            \n",
        "dat = pd.DataFrame.from_dict(d_data)\n",
        "\n",
        "\n",
        "selected = ['image_id',\n",
        "'Eyeglasses',\n",
        " 'Wearing_Earrings',\n",
        " 'Wearing_Hat',\n",
        " 'Wearing_Necklace',\n",
        " 'Wearing_Necktie',\n",
        " 'No_Beard',\n",
        " 'Smiling']\n",
        "\n",
        "def is_label(row):\n",
        "    for s in selected[1:]:\n",
        "        if row[s]!=0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_loc(i):\n",
        "    return os.path.join(os.getcwd(),'img_align_celeba/')+i\n",
        "\n",
        "dat_label = dat.apply(is_label,axis=1)\n",
        "dat_selected = dat[dat_label][selected]\n",
        "dat_selected['image_path'] = dat_selected['image_id'].map(lambda x:get_loc(x))\n",
        "selected[0] = 'image_path'\n",
        "\n",
        "df = dat_selected[selected]\n",
        "set_lab = {}\n",
        "for i,row in df.iterrows():\n",
        "    q = str(row.tolist()[1:])\n",
        "    if q not in set_lab:\n",
        "        set_lab[(str(q))]=len(set_lab)\n",
        "\n",
        "# Here we drop a couple rare class-combinations just to simplify stratified data splitting\n",
        "def get_lab(row):\n",
        "    q = str(row.tolist()[1:])\n",
        "    return set_lab[q]\n",
        "\n",
        "df['unique_label'] = df.apply(get_lab,axis=1)\n",
        "cnt = Counter(df['unique_label'])\n",
        "\n",
        "def drop(val):\n",
        "    if cnt[val]>10:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "is_drop = df['unique_label'].apply(lambda x:drop(x))\n",
        "df = df[is_drop]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ot25HS3syiJ"
      },
      "source": [
        "The resulting DataFrame contains the ID of each image and the classes (i.e. *tags*) that apply to this image.\n",
        "\n",
        "We define a general class of Pytorch neural networks for multi-label image classification. You can use this class for training models on *any* image dataset, and this class can utilize *any* pretrained [TIMM](https://timm.fast.ai/) network backbone. The `MultiLabelModel` below adds an appropriate output layer on top of the network backbone and then fine-tunes the entire network jointly on your multi-label classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3R6gK_HlsyiJ"
      },
      "outputs": [],
      "source": [
        "class MultiLabelModel(nn.Module):\n",
        "    \"\"\" \n",
        "    Pytorch network for multi-label classification that can utilize any TIMM network backbone.\n",
        "    Some of this code is inspired by: https://github.com/yang-ruixin/PyTorch-Image-Models-Multi-Label-Classification\n",
        "    Note this network uses Sigmoid output activations because the predicted probabilities do not need to sum to 1\n",
        "    for multi-label classification, in which each image may belong to multiple classes rather than only one.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, n_classes, class_weights=None, verbose = False):\n",
        "        super().__init__()\n",
        "        self.base_model = model  # network backbone can be any TIMM model\n",
        "        self.num_classes = n_classes\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_loss(self, loss_fn, output, target):\n",
        "\n",
        "        return loss_fn(output, target)\n",
        "\n",
        "    def validate(self, loader):\n",
        "        self.eval();\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            m = nn.Sigmoid()\n",
        "            labels = []\n",
        "            preds = []\n",
        "            for batch_idx, (input, target) in enumerate(loader):\n",
        "                input = input.cuda()\n",
        "                labels.append(target.detach().cpu())\n",
        "                target = target.float().cuda()\n",
        "                output = m(self(input))\n",
        "                loss = self.get_loss(loss_fn, output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred_model = (output > 0.5).detach().cpu()\n",
        "                preds.append(pred_model)\n",
        "\n",
        "            num_of_batches_per_epoch = len(loader)\n",
        "            avg_loss = total_loss / num_of_batches_per_epoch\n",
        "            print(\"VALIDATION DATA STATS\")\n",
        "\n",
        "            print(\"AVERAGE LOSS:\", avg_loss)\n",
        "            preds = torch.cat(preds).int()\n",
        "            labels = torch.cat(labels).int()\n",
        "            acc_score = accuracy_score(labels, preds)\n",
        "            print(\"MULTILABEL accuracy score:\", acc_score)\n",
        "            per_class = []\n",
        "            for i in range(len(preds.T)):\n",
        "                per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
        "            print(dataset_train.label_names)\n",
        "            print(per_class)\n",
        "            print('\\n\\n')\n",
        "        return avg_loss\n",
        "\n",
        "    def predict_proba(self, loader):\n",
        "        self.eval();\n",
        "        with torch.no_grad():\n",
        "            m = nn.Sigmoid()\n",
        "            preds = []\n",
        "            for batch_idx, (input, target) in enumerate(loader):\n",
        "                input = input.cuda()\n",
        "                output = m(self(input))\n",
        "                pred_model = output.detach().cpu()\n",
        "                preds.append(pred_model)\n",
        "            preds = torch.cat(preds)\n",
        "        return preds\n",
        "\n",
        "    def train_one_epoch(\n",
        "        self,\n",
        "        loader,\n",
        "        optimizer,\n",
        "        loss_fn,\n",
        "    ):\n",
        "        sta = time.time()\n",
        "        second_order = hasattr(optimizer, \"is_second_order\") and optimizer.is_second_order\n",
        "        self.train()\n",
        "        total_loss = 0\n",
        "        m = nn.Sigmoid()\n",
        "        labels = []\n",
        "        preds = []\n",
        "        ct = 0\n",
        "        for batch_idx, (input, target) in tqdm(enumerate(loader)):\n",
        "            input = input.cuda()\n",
        "            ct += 1\n",
        "            labels.append(target.detach().cpu())\n",
        "            target = target.float().cuda()\n",
        "            output = m(self(input))\n",
        "            loss = self.get_loss(loss_fn, output, target)\n",
        "            total_loss += loss.item()\n",
        "            pred_model = (output > 0.5).detach().cpu()\n",
        "            preds.append(pred_model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(create_graph=second_order)\n",
        "            optimizer.step()\n",
        "            if ct % 80 == 0 and self.verbose:\n",
        "                print(\"LOSS:\", loss.item())\n",
        "        num_of_batches_per_epoch = len(loader)\n",
        "        avg_loss = total_loss / num_of_batches_per_epoch\n",
        "        print(\"TRAINING DATA STATS\")\n",
        "        print(\"AVERAGE LOSS:\", avg_loss)\n",
        "        preds = torch.cat(preds).int()\n",
        "        labels = torch.cat(labels).int()\n",
        "        acc_score = accuracy_score(labels, preds)\n",
        "        print(\"MULTILABEL accuracy score:\", acc_score)\n",
        "        per_class = []\n",
        "        for i in range(len(preds.T)):\n",
        "            per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
        "        print(dataset_train.label_names)\n",
        "        print(per_class)\n",
        "        print('\\n\\n')\n",
        "        sto = time.time()\n",
        "        print(\"training time\", sto - sta)\n",
        "        return avg_loss\n",
        "    \n",
        "\n",
        "    def fit(self, loader_train, load_val, num_epochs=10):\n",
        "        if os.path.exists(\"weights_model\"):\n",
        "            print(\"removing weights directory\")\n",
        "            os.system('rm -rf weights_model')\n",
        "        os.mkdir(\"weights_model\")\n",
        "        args = SimpleNamespace()\n",
        "        args.weight_decay = 0\n",
        "        args.lr = 1e-4\n",
        "        args.opt = 'adam'\n",
        "        args.momentum = 0.9\n",
        "        args.sched = \"step\"\n",
        "\n",
        "        optimizer = create_optimizer(args, self)\n",
        "        saver = CheckpointSaver(\n",
        "            model=self,\n",
        "            optimizer=optimizer,\n",
        "            checkpoint_dir=\"weights_model\"\n",
        "        )\n",
        "        errs = []\n",
        "        num_of_data_train = len(loader_train.dataset.data)\n",
        "        for epoch in range(0, num_epochs):\n",
        "            loss_train = self.train_one_epoch(\n",
        "                loader_train,\n",
        "                optimizer,\n",
        "                loss_fn,\n",
        "            )\n",
        "            loss_val = self.validate(loader_val)\n",
        "            errs.append([loss_train, loss_val])\n",
        "            saver.save_checkpoint(epoch, metric=loss_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tzJSxklsyiJ"
      },
      "source": [
        "We also create a wrapper class for training our `MultiLabel` model on multi-label classification image datasets. You can easily apply this to your own datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "XinPsZMAsyiJ"
      },
      "outputs": [],
      "source": [
        "class DatasetMultiLabel(data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            annotation_path=None,\n",
        "            df = None,\n",
        "            transform=None):\n",
        "\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_names = []\n",
        "        if annotation_path is None:\n",
        "            assert df is not None\n",
        "        else:\n",
        "            df = pd.read_csv(annotation_path)\n",
        "        \n",
        "        cols = df.columns\n",
        "        self.label_names = list(cols[1:-1])\n",
        "        for i,row in df.iterrows():\n",
        "            lb = []\n",
        "            for j in cols:\n",
        "                if j=='unique_label':\n",
        "                    continue\n",
        "                if j=='image_path':\n",
        "                    self.data.append(row[j])\n",
        "                else:\n",
        "                    lb.append(float(row[j]))\n",
        "            self.labels.append(lb)\n",
        "                \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        return img, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "t8ZmlRgmsyiK"
      },
      "outputs": [],
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "  Re-initializes model weights, eg. between cross-validation folds. \n",
        "  '''\n",
        "  for layer in m.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "def create_df(pred_probs, dataset):\n",
        "    \"\"\"\n",
        "    Returns a dataframe with image_path and predicted probabilities for each image.\n",
        "    \"\"\"\n",
        "    ls = dataset_val.label_names\n",
        "    cl = defaultdict(list)\n",
        "    cl['image_path'] = dataset.data\n",
        "    for i in range(0,len(ls)):\n",
        "        cl[ls[i]] = pred_val.T[i].tolist()\n",
        "    return pd.DataFrame.from_dict(cl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JOnvcjLsyiK"
      },
      "source": [
        "Let's create a `DatasetMultiLabel` and `MultiLabelModel` for the Celeb-A dataset. Here we use the [efficientnet_b0](https://rwightman.github.io/pytorch-image-models/models/tf-efficientnet/) backbone for our neural network, but you can easily use any other TIMM backbone. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "9kJiRTF3syiK"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetMultiLabel(df = df)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "model = create_model(\n",
        "    'efficientnet_b0',  # you can replace this with any TIMM backbone\n",
        "    num_classes=len(dataset.labels[0]),\n",
        ")\n",
        "data_config = resolve_data_config(\n",
        "       args = {}, model=model\n",
        "    )\n",
        "data_config[\"input_size\"] = (3, 32, 32)\n",
        "model = MultiLabelModel(\n",
        "        model,\n",
        "        n_classes=len(dataset.labels[0]),\n",
        "    ).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neb9dj-usyiK"
      },
      "source": [
        "We train this network using K-fold cross validation. This allows us to obtain **out-of-sample** predictions for each image in the dataset (i.e. predictions from a copy of the model which never saw this image during training). Out-of-sample predictions are less prone to overfitting, and thus better suited for finding label issues. From each fold of cross-validation, we store the predicted class probabilities for the images that were out-of-sample in a DataFrame `df_pred`. These predictions are subsequently used for finding label issues in cleanlab's Tutorial on [Multi-Label Classification](https://docs.cleanlab.ai/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2XQp-cHpsyiL"
      },
      "outputs": [],
      "source": [
        "num_splits = 2  # number of cross-validation splits (higher values will take longer but give better results)\n",
        "skf = StratifiedKFold(n_splits=num_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "0e6d3kJxsyiL",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "removing weights directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "188it [00:48,  3.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING DATA STATS\n",
            "AVERAGE LOSS: 1.3429630997967212\n",
            "MULTILABEL accuracy score: 0.1914787234042553\n",
            "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
            "[0.8731489361702127, 0.7407446808510638, 0.8840957446808511, 0.7922234042553191, 0.8586702127659575, 0.782563829787234, 0.5045851063829787]\n",
            "\n",
            "\n",
            "\n",
            "training time 48.6141881942749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VALIDATION DATA STATS\n",
            "AVERAGE LOSS: 0.4749027927401205\n",
            "MULTILABEL accuracy score: 0.26598468189978436\n",
            "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
            "[0.916972072617568, 0.7926426378575905, 0.9459192453551738, 0.8649521442153457, 0.9135515259674729, 0.8928689038316496, 0.5250751564209609]\n",
            "\n",
            "\n",
            "\n",
            "removing weights directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "188it [00:49,  3.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING DATA STATS\n",
            "AVERAGE LOSS: 0.4306276840098361\n",
            "MULTILABEL accuracy score: 0.2398191489361702\n",
            "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
            "[0.9177872340425532, 0.7653191489361703, 0.9204893617021277, 0.853095744680851, 0.9091170212765958, 0.8769255319148936, 0.5245]\n",
            "\n",
            "\n",
            "\n",
            "training time 49.3691520690918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VALIDATION DATA STATS\n",
            "AVERAGE LOSS: 0.3744510628243603\n",
            "MULTILABEL accuracy score: 0.2624288263788561\n",
            "['Eyeglasses', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'No_Beard', 'Smiling']\n",
            "[0.9302923429931164, 0.7971551797399508, 0.9481069941361434, 0.8679569983853148, 0.9220383275261324, 0.8982748364069006, 0.5427891561145577]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ct = 1\n",
        "for train_index, test_index in skf.split(df,df['unique_label']):\n",
        "    if ct!=1:\n",
        "        model.apply(reset_weights);\n",
        "    dataset_train = DatasetMultiLabel(df = df.iloc[train_index])\n",
        "    dataset_val = DatasetMultiLabel(df = df.iloc[test_index])\n",
        "    loader_train = create_loader(\n",
        "        dataset_train,\n",
        "        input_size=data_config[\"input_size\"],\n",
        "        batch_size=500,\n",
        "        is_training=True,\n",
        "        mean=data_config[\"mean\"],\n",
        "        std=data_config[\"std\"],\n",
        "       interpolation=data_config[\"interpolation\"],\n",
        "    )\n",
        "    loader_val = create_loader(\n",
        "        dataset_val,\n",
        "        input_size=data_config[\"input_size\"],\n",
        "        batch_size=500,\n",
        "        is_training=False,\n",
        "        mean=data_config[\"mean\"],\n",
        "        std=data_config[\"std\"],\n",
        "        interpolation=data_config[\"interpolation\"],\n",
        "\n",
        "    )\n",
        "    model.fit(loader_train,loader_val,num_epochs=1)\n",
        "    checkpoint = torch.load(\"weights_model/model_best.pth.tar\")\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    pred_val = model.predict_proba(loader_val)\n",
        "    df_pred = create_df(pred_val,dataset_val)\n",
        "    df_pred.to_csv(str(ct)+\"_fold.csv\",index=False)\n",
        "    ct+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dnmlt5YxsyiL"
      },
      "outputs": [],
      "source": [
        "dfl = []\n",
        "for i in range(1,num_splits+1):\n",
        "    dfl.append(pd.read_csv(str(i)+\"_fold.csv\"))\n",
        "\n",
        "cols = dfl[0].columns[1:]\n",
        "df_pred = pd.concat(dfl,axis=0)\n",
        "df_pred['image_path'] = (df_pred['image_path'].map(lambda x:x.split('/')[-1]))\n",
        "df_pred.set_index('image_path').to_csv(\"pred_probs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Smiling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>0.213967</td>\n",
              "      <td>0.230944</td>\n",
              "      <td>0.120494</td>\n",
              "      <td>0.112896</td>\n",
              "      <td>0.297117</td>\n",
              "      <td>0.810098</td>\n",
              "      <td>0.410487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0.175427</td>\n",
              "      <td>0.222502</td>\n",
              "      <td>0.099109</td>\n",
              "      <td>0.203868</td>\n",
              "      <td>0.165654</td>\n",
              "      <td>0.844859</td>\n",
              "      <td>0.402193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>0.121280</td>\n",
              "      <td>0.216154</td>\n",
              "      <td>0.076970</td>\n",
              "      <td>0.147503</td>\n",
              "      <td>0.115196</td>\n",
              "      <td>0.903464</td>\n",
              "      <td>0.486187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>0.146671</td>\n",
              "      <td>0.226989</td>\n",
              "      <td>0.082455</td>\n",
              "      <td>0.169462</td>\n",
              "      <td>0.133613</td>\n",
              "      <td>0.884957</td>\n",
              "      <td>0.497215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>0.181739</td>\n",
              "      <td>0.251470</td>\n",
              "      <td>0.066860</td>\n",
              "      <td>0.170052</td>\n",
              "      <td>0.139145</td>\n",
              "      <td>0.857879</td>\n",
              "      <td>0.526083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94131</th>\n",
              "      <td>202595.jpg</td>\n",
              "      <td>0.057444</td>\n",
              "      <td>0.217195</td>\n",
              "      <td>0.048693</td>\n",
              "      <td>0.142870</td>\n",
              "      <td>0.067489</td>\n",
              "      <td>0.917330</td>\n",
              "      <td>0.522584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94132</th>\n",
              "      <td>202596.jpg</td>\n",
              "      <td>0.048415</td>\n",
              "      <td>0.224178</td>\n",
              "      <td>0.038581</td>\n",
              "      <td>0.144111</td>\n",
              "      <td>0.060461</td>\n",
              "      <td>0.915048</td>\n",
              "      <td>0.552987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94133</th>\n",
              "      <td>202597.jpg</td>\n",
              "      <td>0.123990</td>\n",
              "      <td>0.228380</td>\n",
              "      <td>0.130657</td>\n",
              "      <td>0.126525</td>\n",
              "      <td>0.097333</td>\n",
              "      <td>0.861600</td>\n",
              "      <td>0.421455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94134</th>\n",
              "      <td>202598.jpg</td>\n",
              "      <td>0.078667</td>\n",
              "      <td>0.159727</td>\n",
              "      <td>0.078418</td>\n",
              "      <td>0.110420</td>\n",
              "      <td>0.070555</td>\n",
              "      <td>0.886762</td>\n",
              "      <td>0.564058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94135</th>\n",
              "      <td>202599.jpg</td>\n",
              "      <td>0.094078</td>\n",
              "      <td>0.173813</td>\n",
              "      <td>0.088059</td>\n",
              "      <td>0.129462</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.878001</td>\n",
              "      <td>0.498944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188273 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_path  Eyeglasses  Wearing_Earrings  Wearing_Hat  \\\n",
              "0      000001.jpg    0.213967          0.230944     0.120494   \n",
              "1      000002.jpg    0.175427          0.222502     0.099109   \n",
              "2      000003.jpg    0.121280          0.216154     0.076970   \n",
              "3      000004.jpg    0.146671          0.226989     0.082455   \n",
              "4      000005.jpg    0.181739          0.251470     0.066860   \n",
              "...           ...         ...               ...          ...   \n",
              "94131  202595.jpg    0.057444          0.217195     0.048693   \n",
              "94132  202596.jpg    0.048415          0.224178     0.038581   \n",
              "94133  202597.jpg    0.123990          0.228380     0.130657   \n",
              "94134  202598.jpg    0.078667          0.159727     0.078418   \n",
              "94135  202599.jpg    0.094078          0.173813     0.088059   \n",
              "\n",
              "       Wearing_Necklace  Wearing_Necktie  No_Beard   Smiling  \n",
              "0              0.112896         0.297117  0.810098  0.410487  \n",
              "1              0.203868         0.165654  0.844859  0.402193  \n",
              "2              0.147503         0.115196  0.903464  0.486187  \n",
              "3              0.169462         0.133613  0.884957  0.497215  \n",
              "4              0.170052         0.139145  0.857879  0.526083  \n",
              "...                 ...              ...       ...       ...  \n",
              "94131          0.142870         0.067489  0.917330  0.522584  \n",
              "94132          0.144111         0.060461  0.915048  0.552987  \n",
              "94133          0.126525         0.097333  0.861600  0.421455  \n",
              "94134          0.110420         0.070555  0.886762  0.564058  \n",
              "94135          0.129462         0.078947  0.878001  0.498944  \n",
              "\n",
              "[188273 rows x 8 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from cleanlab.filter import find_label_issues\n",
        "from cleanlab.internal.multilabel_utils import onehot2int\n",
        "\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred = pd.read_csv(\"pred_probs.csv\").set_index('image_path').sort_index()\n",
        "DATA =(\"image_path \" + open(\"list_attr_celeba.txt\").read()[7:]).splitlines()\n",
        "\n",
        "from collections import defaultdict\n",
        "q = DATA[0]\n",
        "d_data = defaultdict(list)\n",
        "ls = q.split()\n",
        "for i in q.split():\n",
        "    d_data[i] = []\n",
        "for j in DATA[1:]:\n",
        "    labels = j.split()\n",
        "    for k in range(0,len(labels)):\n",
        "        if k==0:\n",
        "            d_data[ls[k]].append(labels[k])\n",
        "        else:\n",
        "            ps = int((int(labels[k])+1)/2)\n",
        "            d_data[ls[k]].append(ps)\n",
        "\n",
        "df = pd.DataFrame.from_dict(d_data).set_index(\"image_path\").loc[df_pred.index].sort_index()\n",
        "class_names = df_pred.columns\n",
        "binarized_labels = df[class_names].to_numpy()\n",
        "pred_probs = df_pred[class_names].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label_name(ls):\n",
        "    return [class_names[i] for i in ls]\n",
        "\n",
        "def get_image_loc(s):\n",
        "    return os.getcwd() + \"/img_align_celeba/\" + s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 0, ..., 0, 1, 1],\n",
              "       [0, 0, 0, ..., 0, 1, 1],\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 0, 1, 1],\n",
              "       [0, 1, 0, ..., 0, 1, 1],\n",
              "       [0, 0, 0, ..., 0, 1, 0]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "binarized_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = onehot2int(binarized_labels)  # label for each image in the format required by cleanlab (integer class indices)\n",
        "pred_labels = onehot2int(np.array((pred_probs > 0.5), np.int32))  # predicted classes to which each image belongs, according to our model\n",
        "image_names = np.array([get_image_loc(i) for i in df.index])  # name of file for each image\n",
        "pred_label_names = [get_label_name(i) for i in pred_labels]  # class predictions in terms of original class names\n",
        "label_names = [get_label_name(i) for i in labels]  # image labels in terms of original class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [4, 5],\n",
              " [6],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [3, 5],\n",
              " [4, 5, 6],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [1, 3, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [2],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [0],\n",
              " [3, 5, 6],\n",
              " [4, 5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [2, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [1, 2, 5],\n",
              " [5],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [1, 3, 5],\n",
              " [3, 5],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [0, 3, 5],\n",
              " [3, 5, 6],\n",
              " [1, 2, 5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [4],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [0],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5],\n",
              " [4, 5, 6],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [4, 6],\n",
              " [4, 5, 6],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [6],\n",
              " [4, 5, 6],\n",
              " [2, 6],\n",
              " [2, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [0],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [2, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0, 4, 5, 6],\n",
              " [4, 5, 6],\n",
              " [0, 2],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [1, 5],\n",
              " [1, 5],\n",
              " [4],\n",
              " [5],\n",
              " [2],\n",
              " [3, 5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [0, 5],\n",
              " [0, 3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [0],\n",
              " [6],\n",
              " [2, 6],\n",
              " [2, 5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [2],\n",
              " [1, 5],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 6],\n",
              " [2],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [4, 5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [0],\n",
              " [6],\n",
              " [1, 5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [0, 5],\n",
              " [5],\n",
              " [5],\n",
              " [0, 5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 2, 5],\n",
              " [6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [0, 4, 5],\n",
              " [5],\n",
              " [0],\n",
              " [1, 3, 5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [6],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [0, 5],\n",
              " [0, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [3, 5],\n",
              " [6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5],\n",
              " [3, 5],\n",
              " [1, 3, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [4, 5],\n",
              " [6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [4, 5],\n",
              " [4, 6],\n",
              " [2, 5],\n",
              " [5, 6],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [2],\n",
              " [5],\n",
              " [6],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [4, 5],\n",
              " [1, 3, 5, 6],\n",
              " [3, 5],\n",
              " [4, 5, 6],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [4],\n",
              " [0, 4, 5, 6],\n",
              " [5],\n",
              " [1, 3, 5],\n",
              " [2],\n",
              " [5, 6],\n",
              " [0, 2, 5],\n",
              " [6],\n",
              " [5],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [3, 5],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [1, 2, 3, 5],\n",
              " [5, 6],\n",
              " [0, 4],\n",
              " [1, 3, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [1, 3, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [2, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0, 3, 5],\n",
              " [5],\n",
              " [0, 1, 5, 6],\n",
              " [5, 6],\n",
              " [3, 5],\n",
              " [6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [0],\n",
              " [1, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0, 5],\n",
              " [4, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [3, 5],\n",
              " [5],\n",
              " [2, 5],\n",
              " [5],\n",
              " [2],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [2],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [6],\n",
              " [5],\n",
              " [2, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [1, 3, 5],\n",
              " [1, 3, 5, 6],\n",
              " [4, 5, 6],\n",
              " [5, 6],\n",
              " [4, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [4, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4],\n",
              " [0, 4, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0],\n",
              " [1, 6],\n",
              " [5],\n",
              " [4],\n",
              " [0, 1, 5],\n",
              " [4, 6],\n",
              " [2],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [3],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [2, 5],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [0, 3, 5],\n",
              " [5, 6],\n",
              " [0, 3, 5, 6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [3, 5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [2, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [3, 5],\n",
              " [0],\n",
              " [2, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [0],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [4],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [4, 5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [3, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [4, 6],\n",
              " [5],\n",
              " [5],\n",
              " [6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0, 5, 6],\n",
              " [1, 5],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [0, 2, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [0, 5, 6],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 3, 5],\n",
              " [1, 3, 5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [0, 1],\n",
              " [6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [0, 5],\n",
              " [6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [0, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [2, 5, 6],\n",
              " [6],\n",
              " [1, 2],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [3, 5],\n",
              " [6],\n",
              " [5],\n",
              " [2, 6],\n",
              " [3, 5],\n",
              " [4, 6],\n",
              " [5, 6],\n",
              " [4, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [1, 3, 5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [2, 5],\n",
              " [0, 1, 3, 5],\n",
              " [0],\n",
              " [0, 3, 5, 6],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [0, 5],\n",
              " [5],\n",
              " [5],\n",
              " [6],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [0, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0, 4, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0, 3, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [2, 4],\n",
              " [5],\n",
              " [5],\n",
              " [6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [2, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [2, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [6],\n",
              " [4],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0, 3, 5],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 2, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [3, 5],\n",
              " [4, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [0, 2],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 3, 5],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [0, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [6],\n",
              " [0, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [4],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [0, 5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [2, 5, 6],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [2, 5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [4, 5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [2, 5],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [4, 5],\n",
              " [2, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [1, 5],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [4, 5],\n",
              " [6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [0, 6],\n",
              " [4],\n",
              " [0],\n",
              " [0, 5, 6],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [0, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [3, 5, 6],\n",
              " [3, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 3, 5],\n",
              " [0],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [2, 3],\n",
              " [5],\n",
              " [0, 4, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [0, 4, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [0, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5],\n",
              " [1, 5],\n",
              " [0, 4, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [0, 4, 5],\n",
              " [2, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [1, 3, 5, 6],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [1, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [3, 5],\n",
              " [4, 5],\n",
              " [5],\n",
              " [4],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [3, 5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [6],\n",
              " [5],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [5],\n",
              " [5],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [4, 5],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [3, 5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [4, 6],\n",
              " [1, 5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [0, 1, 5],\n",
              " [1, 5, 6],\n",
              " [2, 3],\n",
              " [5, 6],\n",
              " [0, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [1, 5],\n",
              " [2, 5],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [2, 5],\n",
              " [5],\n",
              " [5],\n",
              " [5],\n",
              " [1, 5, 6],\n",
              " [5],\n",
              " [4, 5, 6],\n",
              " [1, 5, 6],\n",
              " [1, 3, 5, 6],\n",
              " [5],\n",
              " [0],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " [2, 4],\n",
              " [3, 5, 6],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [1, 5, 6],\n",
              " [5, 6],\n",
              " [0, 5, 6],\n",
              " [3, 5],\n",
              " [5, 6],\n",
              " [3, 5, 6],\n",
              " [5],\n",
              " [5, 6],\n",
              " [5],\n",
              " [5],\n",
              " [5, 6],\n",
              " ...]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pred_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels for first 3 examples in cleanlab format:\n",
            "[[1, 5, 6], [5, 6], [5]]\n",
            "pred_probs for first 3 examples in cleanlab format:\n",
            "[[0.21396729 0.23094364 0.12049425 0.11289628 0.29711702 0.81009769\n",
            "  0.41048697]\n",
            " [0.17542657 0.22250192 0.09910902 0.2038683  0.16565426 0.8448593\n",
            "  0.40219277]\n",
            " [0.12127966 0.21615355 0.07696974 0.14750262 0.11519588 0.90346438\n",
            "  0.4861871 ]]\n"
          ]
        }
      ],
      "source": [
        "num_to_display = 3  # increase this to see more examples\n",
        "\n",
        "print(f\"labels for first {num_to_display} examples in cleanlab format:\")\n",
        "print(labels[:num_to_display])\n",
        "print(f\"pred_probs for first {num_to_display} examples in cleanlab format:\")\n",
        "print(pred_probs[:num_to_display])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_image(pos, pred_label=None):\n",
        "    \"\"\" Plots particular CelebA image and its label, and optionally the model-predicted label as well. \"\"\"\n",
        "    label_error = label_names[pos]\n",
        "    path = image_names[pos]\n",
        "    img = torchvision.io.read_image(path).swapaxes(0, 2).swapaxes(0, 1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img)\n",
        "    fontsize = 20\n",
        "    plt.text(\n",
        "        200,\n",
        "        30,\n",
        "        image_names[pos].split(\"/\")[-1],\n",
        "        bbox=dict(\n",
        "            fill=False,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=1,\n",
        "        ),\n",
        "        fontsize=fontsize,\n",
        "    )\n",
        "    txt = plt.text(\n",
        "        200,\n",
        "        120,\n",
        "        \"Given Label: \" + str(label_error),\n",
        "        bbox=dict(fill=False, edgecolor=\"red\", linewidth=1),\n",
        "        fontsize=fontsize,\n",
        "        wrap=True,\n",
        "    )\n",
        "    txt._get_wrap_line_width = lambda: 400\n",
        "    if pred_label is not None:\n",
        "        txt = plt.text(\n",
        "            200,\n",
        "            200,\n",
        "            \"Model Predicted: \" + str(pred_label),\n",
        "            bbox=dict(fill=False, edgecolor=\"green\", linewidth=1),\n",
        "            fontsize=fontsize,\n",
        "            wrap=True,\n",
        "        )\n",
        "        txt._get_wrap_line_width = lambda: 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'_OpNamespace' 'image' object has no attribute 'read_file'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_ops.py:501\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     op, overload_names \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_get_operation(qualified_op_name)\n\u001b[1;32m    502\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    503\u001b[0m     \u001b[39m# Turn this into AttributeError so getattr(obj, key, default)\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[39m# works (this is called by TorchScript with __origin__)\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No such operator image::read_file",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m example_to_view \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# you can play with this\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plot_image(example_to_view)\n",
            "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mplot_image\u001b[0;34m(pos, pred_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m label_error \u001b[39m=\u001b[39m label_names[pos]\n\u001b[1;32m      4\u001b[0m path \u001b[39m=\u001b[39m image_names[pos]\n\u001b[0;32m----> 5\u001b[0m img \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_image(path)\u001b[39m.\u001b[39mswapaxes(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mswapaxes(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[39m.\u001b[39mimshow(img)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/io/image.py:253\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m    252\u001b[0m     _log_api_usage_once(read_image)\n\u001b[0;32m--> 253\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/io/image.py:47\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m     46\u001b[0m     _log_api_usage_once(read_file)\n\u001b[0;32m---> 47\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mread_file(path)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_ops.py:505\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m    501\u001b[0m     op, overload_names \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_get_operation(qualified_op_name)\n\u001b[1;32m    502\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    503\u001b[0m     \u001b[39m# Turn this into AttributeError so getattr(obj, key, default)\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[39m# works (this is called by TorchScript with __origin__)\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    506\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_OpNamespace\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mop_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    507\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m# let the script frontend know that op is identical to the builtin op\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m# with qualified_op_name\u001b[39;00m\n\u001b[1;32m    511\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_builtins\u001b[39m.\u001b[39m_register_builtin(op, qualified_op_name)\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_OpNamespace' 'image' object has no attribute 'read_file'"
          ]
        }
      ],
      "source": [
        "example_to_view = 0  # you can play with this\n",
        "plot_image(example_to_view)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "work",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0e8f33c5a67865e6aadcd232beb3e2644a1f224e780847feacdefa5e710f41d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
