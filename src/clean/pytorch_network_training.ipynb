{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjSqDwgxsyiE"
      },
      "source": [
        "# Train a neural network for multi-label classification on the CelebA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeoyWCIYsyiG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/multilabel_classification/pytorch_network_training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfEuwy0ksyiG"
      },
      "source": [
        "This notebook demonstrates how to train a Pytorch neural network for image tagging and use the model to produce out-of-sample predicted class probabilities for each image in the dataset. These are required inputs to find label errors in multi-label classification datasets with cleanlab. Here we consider a subset of the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset, where each image may be tagged with one or more of the following tags: `['Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'Eyeglasses', 'No_Beard', 'Smiling']`, depending on which ones apply to the person depicted.\n",
        "\n",
        "This notebook only shows how to train the network andÂ use it to produce `pred_probs`, using them to find label issues is demonstrated in our other [example](https://github.com/cleanlab/examples/) notebook on [Find Label Errors in Multi-Label Classification Data (CelebA Image Tagging)](https://github.com/cleanlab/examples/blob/multilabel_tutorial/multilabel_classification/image_tagging.ipynb). Here we fit a state-of-the-art neural network initialized from a pretrained [TIMM](https://timm.fast.ai/) network backbone. You can use this same code to obtain a multi-label classifier (i.e. image tagging model) for *any* image dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNzpDVZOsyiG"
      },
      "source": [
        "Please install the dependencies specified in this [requirements.txt](https://github.com/cleanlab/examples/blob/master/multilabel_classification/requirements.txt) file before running the notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga3f-6EQsyiG"
      },
      "source": [
        "Next you need to download the dataset. The below code attempts to download the dataset from the Google Drive where its authors have stored it, but this Drive only allows limited programmatic downloads per day. If the Google Drive download script fails, please just manually download the following links from the [CelebA dataset webpage](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and save them in the current working directory:\n",
        " * [Images](https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM)\n",
        " * [Labels](https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "A_bNsVYCsyiH"
      },
      "outputs": [],
      "source": [
        "# import gdown\n",
        "# import os\n",
        "# def download_drive(url,output):\n",
        "#     filename = gdown.download(url, output, quiet=False)\n",
        "#     if filename is None:\n",
        "#         print(f\"Downloading {url} failed, please download it from browser and paste it in {os.getcwd()}\")\n",
        "# url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U'\n",
        "# output = 'list_attr_celeba.txt'\n",
        "# if not os.path.exists(output):\n",
        "#     download_drive(url,output)\n",
        "# url = 'https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM' # Usually errors out, Download them manually from the link below\n",
        "# output = 'img_align_celeba.zip'\n",
        "# if not os.path.exists(output):\n",
        "#     download_drive(url,output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHb1XrRUsyiH"
      },
      "source": [
        "Remember you can just manually download the data from the link above if this code failed. Once you have downloaded the zipped data file, unzip the folder which contains a bunch of individual image files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "a1ECAnTcsyiI"
      },
      "outputs": [],
      "source": [
        "# !unzip -qq img_align_celeba.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6feD6tYsyiI"
      },
      "source": [
        "Next we import the other required dependencies (make sure you have installed these packages)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P7PgaxmRsyiI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "from types import SimpleNamespace\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data\n",
        "from timm.optim import create_optimizer\n",
        "from timm.models import create_model\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.loader import create_loader\n",
        "from timm.utils import CheckpointSaver\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpHBLtpZsyiI"
      },
      "source": [
        "Now we load the dataset, and preprocess it to only keep the classes of interest (i.e. *image tags*) listed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cRX2LyXisyiI"
      },
      "outputs": [],
      "source": [
        "DATA =(\"image_id \" + open(\"list_attr_celeba.txt\").read()[7:]).splitlines()\n",
        "\n",
        "from collections import defaultdict\n",
        "q = DATA[0]\n",
        "d_data = defaultdict(list)\n",
        "ls = q.split()\n",
        "for i in q.split():\n",
        "    d_data[i] = []\n",
        "for j in DATA[1:]:\n",
        "    labels = j.split()\n",
        "    for k in range(0,len(labels)):\n",
        "        if k==0:\n",
        "            d_data[ls[k]].append(labels[k])\n",
        "        else:\n",
        "            # map -1 entries -> 0\n",
        "            ps = int((int(labels[k])+1)/2)\n",
        "            d_data[ls[k]].append(ps)\n",
        "            \n",
        "dat = pd.DataFrame.from_dict(d_data)\n",
        "\n",
        "\n",
        "selected = ['image_id',\n",
        "'Eyeglasses',\n",
        " 'Wearing_Earrings',\n",
        " 'Wearing_Hat',\n",
        " 'Wearing_Necklace',\n",
        " 'Wearing_Necktie',\n",
        " 'No_Beard',\n",
        " 'Smiling']\n",
        "\n",
        "def is_label(row):\n",
        "    for s in selected[1:]:\n",
        "        if row[s]!=0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_loc(i):\n",
        "    return os.path.join(os.getcwd(),'img_align_celeba/')+i\n",
        "\n",
        "dat_label = dat.apply(is_label,axis=1)\n",
        "dat_selected = dat[dat_label][selected]\n",
        "dat_selected['image_path'] = dat_selected['image_id'].map(lambda x:get_loc(x))\n",
        "selected[0] = 'image_path'\n",
        "\n",
        "df = dat_selected[selected]\n",
        "set_lab = {}\n",
        "for i,row in df.iterrows():\n",
        "    q = str(row.tolist()[1:])\n",
        "    if q not in set_lab:\n",
        "        set_lab[(str(q))]=len(set_lab)\n",
        "\n",
        "# Here we drop a couple rare class-combinations just to simplify stratified data splitting\n",
        "def get_lab(row):\n",
        "    q = str(row.tolist()[1:])\n",
        "    return set_lab[q]\n",
        "\n",
        "df['unique_label'] = df.apply(get_lab,axis=1)\n",
        "cnt = Counter(df['unique_label'])\n",
        "\n",
        "def drop(val):\n",
        "    if cnt[val]>10:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "is_drop = df['unique_label'].apply(lambda x:drop(x))\n",
        "df = df[is_drop]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ot25HS3syiJ"
      },
      "source": [
        "The resulting DataFrame contains the ID of each image and the classes (i.e. *tags*) that apply to this image.\n",
        "\n",
        "We define a general class of Pytorch neural networks for multi-label image classification. You can use this class for training models on *any* image dataset, and this class can utilize *any* pretrained [TIMM](https://timm.fast.ai/) network backbone. The `MultiLabelModel` below adds an appropriate output layer on top of the network backbone and then fine-tunes the entire network jointly on your multi-label classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3R6gK_HlsyiJ"
      },
      "outputs": [],
      "source": [
        "class MultiLabelModel(nn.Module):\n",
        "    \"\"\" \n",
        "    Pytorch network for multi-label classification that can utilize any TIMM network backbone.\n",
        "    Some of this code is inspired by: https://github.com/yang-ruixin/PyTorch-Image-Models-Multi-Label-Classification\n",
        "    Note this network uses Sigmoid output activations because the predicted probabilities do not need to sum to 1\n",
        "    for multi-label classification, in which each image may belong to multiple classes rather than only one.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, n_classes, class_weights=None, verbose = False):\n",
        "        super().__init__()\n",
        "        self.base_model = model  # network backbone can be any TIMM model\n",
        "        self.num_classes = n_classes\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_loss(self, loss_fn, output, target):\n",
        "\n",
        "        return loss_fn(output, target)\n",
        "\n",
        "    def validate(self, loader):\n",
        "        self.eval();\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            m = nn.Sigmoid()\n",
        "            labels = []\n",
        "            preds = []\n",
        "            for batch_idx, (input, target) in enumerate(loader):\n",
        "                input = input.cuda()\n",
        "                labels.append(target.detach().cpu())\n",
        "                target = target.float().cuda()\n",
        "                output = m(self(input))\n",
        "                loss = self.get_loss(loss_fn, output, target)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pred_model = (output > 0.5).detach().cpu()\n",
        "                preds.append(pred_model)\n",
        "\n",
        "            num_of_batches_per_epoch = len(loader)\n",
        "            avg_loss = total_loss / num_of_batches_per_epoch\n",
        "            print(\"VALIDATION DATA STATS\")\n",
        "\n",
        "            print(\"AVERAGE LOSS:\", avg_loss)\n",
        "            preds = torch.cat(preds).int()\n",
        "            labels = torch.cat(labels).int()\n",
        "            acc_score = accuracy_score(labels, preds)\n",
        "            print(\"MULTILABEL accuracy score:\", acc_score)\n",
        "            per_class = []\n",
        "            for i in range(len(preds.T)):\n",
        "                per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
        "            print(dataset_train.label_names)\n",
        "            print(per_class)\n",
        "            print('\\n\\n')\n",
        "        return avg_loss\n",
        "\n",
        "    def predict_proba(self, loader):\n",
        "        self.eval();\n",
        "        with torch.no_grad():\n",
        "            m = nn.Sigmoid()\n",
        "            preds = []\n",
        "            for batch_idx, (input, target) in enumerate(loader):\n",
        "                input = input.cuda()\n",
        "                output = m(self(input))\n",
        "                pred_model = output.detach().cpu()\n",
        "                preds.append(pred_model)\n",
        "            preds = torch.cat(preds)\n",
        "        return preds\n",
        "\n",
        "    def train_one_epoch(\n",
        "        self,\n",
        "        loader,\n",
        "        optimizer,\n",
        "        loss_fn,\n",
        "    ):\n",
        "        sta = time.time()\n",
        "        second_order = hasattr(optimizer, \"is_second_order\") and optimizer.is_second_order\n",
        "        self.train()\n",
        "        total_loss = 0\n",
        "        m = nn.Sigmoid()\n",
        "        labels = []\n",
        "        preds = []\n",
        "        ct = 0\n",
        "        for batch_idx, (input, target) in tqdm(enumerate(loader)):\n",
        "            input = input.cuda()\n",
        "            ct += 1\n",
        "            labels.append(target.detach().cpu())\n",
        "            target = target.float().cuda()\n",
        "            output = m(self(input))\n",
        "            loss = self.get_loss(loss_fn, output, target)\n",
        "            total_loss += loss.item()\n",
        "            pred_model = (output > 0.5).detach().cpu()\n",
        "            preds.append(pred_model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(create_graph=second_order)\n",
        "            optimizer.step()\n",
        "            if ct % 80 == 0 and self.verbose:\n",
        "                print(\"LOSS:\", loss.item())\n",
        "        num_of_batches_per_epoch = len(loader)\n",
        "        avg_loss = total_loss / num_of_batches_per_epoch\n",
        "        print(\"TRAINING DATA STATS\")\n",
        "        print(\"AVERAGE LOSS:\", avg_loss)\n",
        "        preds = torch.cat(preds).int()\n",
        "        labels = torch.cat(labels).int()\n",
        "        acc_score = accuracy_score(labels, preds)\n",
        "        print(\"MULTILABEL accuracy score:\", acc_score)\n",
        "        per_class = []\n",
        "        for i in range(len(preds.T)):\n",
        "            per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
        "        print(dataset_train.label_names)\n",
        "        print(per_class)\n",
        "        print('\\n\\n')\n",
        "        sto = time.time()\n",
        "        print(\"training time\", sto - sta)\n",
        "        return avg_loss\n",
        "    \n",
        "\n",
        "    def fit(self, loader_train, load_val, num_epochs=10):\n",
        "        if os.path.exists(\"weights_model\"):\n",
        "            print(\"removing weights directory\")\n",
        "            os.system('rm -rf weights_model')\n",
        "        os.mkdir(\"weights_model\")\n",
        "        args = SimpleNamespace()\n",
        "        args.weight_decay = 0\n",
        "        args.lr = 1e-4\n",
        "        args.opt = 'adam'\n",
        "        args.momentum = 0.9\n",
        "        args.sched = \"step\"\n",
        "\n",
        "        optimizer = create_optimizer(args, self)\n",
        "        saver = CheckpointSaver(\n",
        "            model=self,\n",
        "            optimizer=optimizer,\n",
        "            checkpoint_dir=\"weights_model\"\n",
        "        )\n",
        "        errs = []\n",
        "        num_of_data_train = len(loader_train.dataset.data)\n",
        "        for epoch in range(0, num_epochs):\n",
        "            loss_train = self.train_one_epoch(\n",
        "                loader_train,\n",
        "                optimizer,\n",
        "                loss_fn,\n",
        "            )\n",
        "            loss_val = self.validate(loader_val)\n",
        "            errs.append([loss_train, loss_val])\n",
        "            saver.save_checkpoint(epoch, metric=loss_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tzJSxklsyiJ"
      },
      "source": [
        "We also create a wrapper class for training our `MultiLabel` model on multi-label classification image datasets. You can easily apply this to your own datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XinPsZMAsyiJ"
      },
      "outputs": [],
      "source": [
        "class DatasetMultiLabel(data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            annotation_path=None,\n",
        "            df = None,\n",
        "            transform=None):\n",
        "\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_names = []\n",
        "        if annotation_path is None:\n",
        "            assert df is not None\n",
        "        else:\n",
        "            df = pd.read_csv(annotation_path)\n",
        "        \n",
        "        cols = df.columns\n",
        "        self.label_names = list(cols[1:-1])\n",
        "        for i,row in df.iterrows():\n",
        "            lb = []\n",
        "            for j in cols:\n",
        "                if j=='unique_label':\n",
        "                    continue\n",
        "                if j=='image_path':\n",
        "                    self.data.append(row[j])\n",
        "                else:\n",
        "                    lb.append(float(row[j]))\n",
        "            self.labels.append(lb)\n",
        "                \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        return img, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "t8ZmlRgmsyiK"
      },
      "outputs": [],
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "  Re-initializes model weights, eg. between cross-validation folds. \n",
        "  '''\n",
        "  for layer in m.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "def create_df(pred_probs, dataset):\n",
        "    \"\"\"\n",
        "    Returns a dataframe with image_path and predicted probabilities for each image.\n",
        "    \"\"\"\n",
        "    ls = dataset_val.label_names\n",
        "    cl = defaultdict(list)\n",
        "    cl['image_path'] = dataset.data\n",
        "    for i in range(0,len(ls)):\n",
        "        cl[ls[i]] = pred_val.T[i].tolist()\n",
        "    return pd.DataFrame.from_dict(cl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JOnvcjLsyiK"
      },
      "source": [
        "Let's create a `DatasetMultiLabel` and `MultiLabelModel` for the Celeb-A dataset. Here we use the [efficientnet_b0](https://rwightman.github.io/pytorch-image-models/models/tf-efficientnet/) backbone for our neural network, but you can easily use any other TIMM backbone. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9kJiRTF3syiK"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetMultiLabel(df = df)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "model = create_model(\n",
        "    'efficientnet_b0',  # you can replace this with any TIMM backbone\n",
        "    num_classes=len(dataset.labels[0]),\n",
        ")\n",
        "data_config = resolve_data_config(\n",
        "       args = {}, model=model\n",
        "    )\n",
        "\n",
        "model = MultiLabelModel(\n",
        "        model,\n",
        "        n_classes=len(dataset.labels[0]),\n",
        "    ).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neb9dj-usyiK"
      },
      "source": [
        "We train this network using K-fold cross validation. This allows us to obtain **out-of-sample** predictions for each image in the dataset (i.e. predictions from a copy of the model which never saw this image during training). Out-of-sample predictions are less prone to overfitting, and thus better suited for finding label issues. From each fold of cross-validation, we store the predicted class probabilities for the images that were out-of-sample in a DataFrame `df_pred`. These predictions are subsequently used for finding label issues in cleanlab's Tutorial on [Multi-Label Classification](https://docs.cleanlab.ai/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2XQp-cHpsyiL"
      },
      "outputs": [],
      "source": [
        "num_splits = 4  # number of cross-validation splits (higher values will take longer but give better results)\n",
        "skf = StratifiedKFold(n_splits=num_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0e6d3kJxsyiL",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "removing weights directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [00:11,  4.10it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 26\u001b[0m\n\u001b[1;32m      7\u001b[0m loader_train \u001b[39m=\u001b[39m create_loader(\n\u001b[1;32m      8\u001b[0m     dataset_train,\n\u001b[1;32m      9\u001b[0m     input_size\u001b[39m=\u001b[39mdata_config[\u001b[39m\"\u001b[39m\u001b[39minput_size\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m    interpolation\u001b[39m=\u001b[39mdata_config[\u001b[39m\"\u001b[39m\u001b[39minterpolation\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m loader_val \u001b[39m=\u001b[39m create_loader(\n\u001b[1;32m     17\u001b[0m     dataset_val,\n\u001b[1;32m     18\u001b[0m     input_size\u001b[39m=\u001b[39mdata_config[\u001b[39m\"\u001b[39m\u001b[39minput_size\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m model\u001b[39m.\u001b[39;49mfit(loader_train,loader_val,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mweights_model/model_best.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
            "Cell \u001b[0;32mIn[35], line 142\u001b[0m, in \u001b[0;36mMultiLabelModel.fit\u001b[0;34m(self, loader_train, load_val, num_epochs)\u001b[0m\n\u001b[1;32m    140\u001b[0m num_of_data_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(loader_train\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mdata)\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, num_epochs):\n\u001b[0;32m--> 142\u001b[0m     loss_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(\n\u001b[1;32m    143\u001b[0m         loader_train,\n\u001b[1;32m    144\u001b[0m         optimizer,\n\u001b[1;32m    145\u001b[0m         loss_fn,\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     loss_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate(loader_val)\n\u001b[1;32m    148\u001b[0m     errs\u001b[39m.\u001b[39mappend([loss_train, loss_val])\n",
            "Cell \u001b[0;32mIn[35], line 99\u001b[0m, in \u001b[0;36mMultiLabelModel.train_one_epoch\u001b[0;34m(self, loader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     98\u001b[0m loss\u001b[39m.\u001b[39mbackward(create_graph\u001b[39m=\u001b[39msecond_order)\n\u001b[0;32m---> 99\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m ct \u001b[39m%\u001b[39m \u001b[39m80\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    101\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLOSS:\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ct = 1\n",
        "for train_index, test_index in skf.split(df,df['unique_label']):\n",
        "    if ct!=1:\n",
        "        model.apply(reset_weights);\n",
        "    dataset_train = DatasetMultiLabel(df = df.iloc[train_index])\n",
        "    dataset_val = DatasetMultiLabel(df = df.iloc[test_index])\n",
        "    loader_train = create_loader(\n",
        "        dataset_train,\n",
        "        input_size=data_config[\"input_size\"],\n",
        "        batch_size=100,\n",
        "        is_training=True,\n",
        "        mean=data_config[\"mean\"],\n",
        "        std=data_config[\"std\"],\n",
        "       interpolation=data_config[\"interpolation\"],\n",
        "    )\n",
        "    loader_val = create_loader(\n",
        "        dataset_val,\n",
        "        input_size=data_config[\"input_size\"],\n",
        "        batch_size=100,\n",
        "        is_training=False,\n",
        "        mean=data_config[\"mean\"],\n",
        "        std=data_config[\"std\"],\n",
        "        interpolation=data_config[\"interpolation\"],\n",
        "\n",
        "    )\n",
        "    model.fit(loader_train,loader_val,num_epochs=1)\n",
        "    checkpoint = torch.load(\"weights_model/model_best.pth.tar\")\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    pred_val = model.predict_proba(loader_val)\n",
        "    df_pred = create_df(pred_val,dataset_val)\n",
        "    df_pred.to_csv(str(ct)+\"_fold.csv\",index=False)\n",
        "    ct+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnmlt5YxsyiL"
      },
      "outputs": [],
      "source": [
        "dfl = []\n",
        "for i in range(1,num_splits+1):\n",
        "    dfl.append(pd.read_csv(str(i)+\"_fold.csv\"))\n",
        "\n",
        "cols = dfl[0].columns[1:]\n",
        "df_pred = pd.concat(dfl,axis=0)\n",
        "df_pred['image_path'] = (df_pred['image_path'].map(lambda x:x.split('/')[-1]))\n",
        "df_pred.set_index('image_path').to_csv(\"pred_probs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "work",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0e8f33c5a67865e6aadcd232beb3e2644a1f224e780847feacdefa5e710f41d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
